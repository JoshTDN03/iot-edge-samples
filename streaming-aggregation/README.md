# Streaming Aggregation Sample

## Description

This is a streaming aggregation sample which can be used to implement your own aggregation needs. There are many reasons why aggregations are important for IOT applications at the edge. While creating rule, instead of every event, you may want to aggregate the last few messages. This is because sensor data are known to be fluctuating. Also, when you run ML/AI models at the edge, you may want to run these models at aggregated data rather than every event. That way your ML/AI will use the less compute resource but delivers the same result.

Once you convert this sample to your own streaming aggregation service, make sure you run thorough testing before deploying to the production landscape. Though this is a Java sample, internally it uses custom rule feature of the Streaming service to compute the aggregation. More in *High Level Design* section.

This sample assumes the user has a working knowledge of SAP Edge Services, and is comfortable programming in Java.  You must be familiar with the Streaming Service Edge Console -> specifically configuring streaming rules.

### What it does?

It basically creates two types of streaming aggregations. We call it persistence aggregation and streaming rule aggregation.

### Persistence Aggregation

The aggregations are calculated in time window. For example, if you define a time window of 30 seconds then, aggregations are calculated at the end of 30 seconds. Then the window is cleared, and it starts accumulating event for next 30 seconds. The sample just saves the aggregated data in to a file. You can extend this to save in the persistence service.

### Streaming Rule Aggregation

The aggregations are calculated in a time window, but aggregation is generated every time new event arrives. Every second, the time window slides one second and so to removing beginning one second data. The calculated streaming aggregations can be sent back to the same  rule in the streaming service that it came from. The aggregation will go as event of the rule.

### How does this Aggregation Service receive input data?

The inputs are received from the Streaming rule. You can define a Custom Rule in the Streaming rule engine. In this setup usually, you tell the rule engine which host and port your custom engine is running. In the JSON configuration of this streaming aggregation service, put the same host and port. With this, the aggregation service will bind this port when it starts. And the streaming rule engine sends data to this port. The data transfer to streaming aggregation service and subscription of the aggregated result back to rule engine are handled by the streaming service.

### How the aggregations are computed?

The streaming aggregation service internally uses streaming engine in another process to compute the aggregation. The aggregation logics  are written in CCL (continuous computation language). Depending on the configuration of the streaming aggregation service, CCL is generated, compiled and run to compute the aggregation.

### How can I use streaming aggregations in the streaming rule
The streaming aggregations created in the aggregation service can be brought back to the custom rule of streaming service as an event. If you need the aggregated data then you can use enterprise plugin to send the aggregated to the appropriate target.

### What is the expected performance?

Aggregations are computed using streaming engine and so performance is highly depend on the available memory and compute resources. The streaming aggregation service runs in a separate process and so there is an inherent network delay to get the event from the streaming service to the aggregation service.

If your aggregation time buckets are small enough - say it doesn’t capture more than few thousands of events within this time, then you wouldn’t see any performance degradation even if data are continuously input at the same speed.

You should test the performance to see if it satisfies your requirements.

### What are the aggregations it supports?

The following 11 aggregations are supported by this sample aggregation service:

AVG, SUM, COUNT, MIN, MAX, MEDIAN, STDDEV (standard deviation), COUNTDISTINCT (count of distinct values), WEIGHTEDAVG (weighted average), LASTVALUE (last value in the time bucket), and FIRSTVALUE (first value in the time bucket). All the aggregations are grouped by device id, sensor id and profile id.

### High Level Design

Under the hood a CCL is automatically generated by this service and using custom rule feature of streaming engine data are passed to this service.

The streaming aggregation service is mainly control by the JSON configuration file. The JSON configuration file has two type of configurations: streams and rules.

1.	Streams: This section defines the supported aggregations and whether a persistence aggregation need to be calculated.
2.	Rules: This section defines what are aggregations are subscribed by a sensor profile and rule.

Depending on the parameters of this JSON configuration, at the start of this service, CCL codes are generated, compiled and started. Once it is started, then the **rule subscription** configuration is published to an internal control stream of this CCL. The CCL can dynamically adjust the rule subscription.

Once it starts, streaming rule which is configured to send data to custom rule can start sending data to this aggregation  service. The same streaming aggregation service can handle data from many sensor profiles.

Depending on the rule subscription, streaming aggregations are published to a pre-defined stream where the streaming rule engine gets the aggregated data.

The streaming aggregation service has a subscriber which listens to the computed persistence aggregations. When it receives the aggregations, it stores these values in to a CSV file. It can be extended to store in persistence service.

### How to change CCL code?

CCL code cannot be changed since it is generated from JSON configuration every time the service starts. Most of the simple things you should be able to handle by simply changing JSON configuration file. If required then you should change CCL generator i.e., CclGen.java.

### How do I deploy this service?

This service is not yet wrapped in OSGI container. If you wrap this in OSGI container then you can use IoT Service to deploy this to the gateway. For now, this sample you need to manually deploy in the gateway. The sections below describes how you build and run this sample at the gateway. One of the extension of this sample is to wrap this with OSGI and deploy from the cloud.

## Requirements

You must have following installed in your system:
1. Java JDK 1.8 or above (https://www.java.com/en/download/)
2. Apache Maven (https://maven.apache.org/download.cgi)
3. Git command line tool (https://git-scm.com/downloads)
4. SAP Edge Services (Cloud or On-premise edition)
5. Packaging tool (Tar utility is usually pre-installed in Linux / WinZip or similar for Windows)

### Edge Services

#### Cloud edition

For cloud edition, you need a working IoT Services Gateway Edge (REST) with the SAP Edge Services Streaming Service installed.

#### On-premise edition (3.0 FP02 or newer)

For on-premise edition you simply need a working install of the Persistence Service and Streaming Service.  These are installed together as described in the Edge Services, on-premise edition online documentation.

## Download and Installation

### Download the sample app
```json
git clone https://github.com/SAP/iot-edge-services-samples.git
cd iot-edge-services-samples
cd streaming-aggregation
```

### Compile and Package

1. Open a shell / command prompt (on Windows as Administrator) and navigate to the `streaming-aggregation` directory.
2. Copy libraries to Maven repository by running following command:
```json
mvn eclipse:eclipse
```
3. The above command will throw errors for streaming libraries. It will also show you the command that you need to run in the command line. Follow those commands to copy all the libraries. Libraries are in $STREAMING_HOME/libj folder.
4. Run following command to compile and build the package:
```json
mvn clean install
```
5. Create tar (for Linux) which will include all the 3rd party jars:
```json
cp aggr-cnf.json target
cd target
tar -cvf ../EdgeAnalytics.tar SampleEdgeAnalytics-null.jar  aggr-cnf.json lib/*.jar
```
6. Create zip (for Windows) which will include all the 3rd party jars:
```json
mkdir EdgeAnalytics
copy aggr-cnf.json EdgeAnalytics
copy target\SampleEdgeAnalytics-null.jar EdgeAnalytics
mkdir EdgeAnalytics\lib
copy target\lib\* EdgeAnalytics\lib
Use WinZip or similar tool to zip the EdgeAnalytics folder
```

## Configuration

By simply changing the JSON file you can control this streaming aggregation service. There are two sections in the JSON file: streams and rules. The streams section is fixed. This means this section must be there for this service to function properly.

Each section in the streams have three fixed and one optional name/value pairs. The properties “name”, “time” and “type” are fixed. The property “persist” is optional. If you put “persist” property for a aggregation then this service will create the aggregation and save in a table.

In the rule section of the JSON file there are three name value pairs you define for each section. These are “ruleId”, “profileId” and “aggr”. This is where you configure which streaming aggregation to send to which streaming rule. You may choose not to have rule section at all. In that case, there will be no streaming aggregations are generated.

###  Example
I have two sensor profiles Temperature_0_1 and Humidity_0_1. I have already defined two CUSTOM RULES : “TempAvg”  and “HumdAvg” one for each profile.

I want to generate AVG and SUM in every 30 seconds for both of these sensor measures and save in the persistence service for later use.

I would also like to bring the streaming AVG of Temperature_0_1 to a rule “TempAvg” and AVG of Humidity_0_1 to a rule “HumdAvg”.

Solution:

1.	First, you configure the streams section of the JSON file. Put “persist”: true as shown below ONLY for the AVG and SUM to indicate the streaming aggregation service to generate and save these persistence aggregations. Also change the value of the “time” to 30 SECONDS for both AVG and SUM.
```json
    {
      "name": "AVGSTREAM",
      "time": "10SEC",
      "type": "AVG",
      "persist": true
    },
    {
      "name": "SUMSTREAM",
      "time": "10SEC",
      "type": "SUM",
      "persist": true
    },
```
2.	Now you need to configure the rule section to indicate that AVG calculated for sensor profiles Temperature_0_1 and Humidity_0_1 should be sent to rules TempAvg and HumdAvg respectively.
```json
    {
      "ruleId": "TempAvg",
      "profileId": "Temperature_0_1",
      "aggr": "AVG"
    },
    {
      "ruleId": "HumidAvg",
      "profileId": "Humdity_0_1",
      "aggr": "AVG"
    }
```
3.	Make sure you have Temperature_0_1 and Humidity_0_1 profiles are created in the rule engine. And also make sure to create CUSTOM RULES TempAvg and HumidAvg for each profile.

4.	Set the host name as localhost and port as 9090 for CUSTOM RULES. Make sure that host and port are same in the in the JSON file.

5.	Once JSON file is changed and saved, you need to restart the streaming aggregation service so that it will regenerate the CCL and start the aggregations.

### Deploy and Run
Here are the steps that you can follow to deploy, run and test it:

1. Un-tar the tar file in to a folder
2. Open the aggr-conf.json file in Notepad
3. Start your gateway if it is already not running
4. Login to the Edge Service’s console using browser: https://localhost
5. If not yet then create a sensor profile: Temperature_0_1
6. Create a CUSTOM rule called: TempAggregation
7. Configure the custom rule with host localhost and port 9090
8. Save it.
9. Copy the sensor profile id and rule id (both are hexadecimal string)
10. Go back to your aggr-conf.json file in the Notepad and in the bottom find the section called “rules” and change the ruleId and profileId for one of the section
11. Save it. Exit the notepad.
12. In the command line, set the STREAMING_HOME. For example, if your "edgeservices" folder is at "c:\Gateway\edgeservices" then your STREAMING_HOME should be set to "C:\Gateway\edgeservices\esp\ESP-5_1"
13. To run aggregation service from command line:
```json
java -jar SampleEdgeAnalytics-null.jar
```
14. Shutdown the gateway and start again
15. Open MQTTBox (if you don’t have then download this for Chrome) and send messages to Edge Service’s Temperature_0_1 sensor profile. You can use other methods to send data to Edge Services too.
16. Check the file for aggregations and events in the UI. If you are using "persist" aggregation then you should see new aggregations are created in the CSV file in the same folder. If you have configured JSON to use aggregations in the rule then you should see the rules events generated in the streaming rule engine.


## Limitations

There are some limitations of what you can do with this aggregation service. Here are the list of functionalities that are supported or not supported:

For Persistence Aggregation:
- You can only define ONE Custom Rule for ONE  sensor profile (sensor data)
- You can define only one type of aggregation once for each sensor profile. You can not define same aggregation type for a sensor profile twice and provide different time windowing property
- You can define one or more unique aggregations for each sensor profile

For Streaming Aggregation:
- You can only define ONE Custom Rule for ONE  sensor profile (sensor data)
- You can define only one type of aggregation once for each sensor profile. You can not define same aggregation type for a sensor profile twice and provide different time windowing property
- You can define one or more unique aggregations for each sensor profile
- You can only bring ONE type of aggregation as an event back to streaming rule engine

## Known Issues

Currently, the on-premise Streaming Service requires the aggregation service to start before you start Edge Services. For any other issues, you can check the log file that this aggregation service generates as well as Edge Services Streaming Service log files located at .../dep_iot_edge/log/

## How to obtain support

These samples are provided "as-is" basis with detailed documentation on how to use them. 

## Copyright and License

Copyright (c) 2018 SAP SE or an SAP affiliate company. All rights reserved.

License provided by [SAP SAMPLE CODE LICENSE AGREEMENT](https://github.com/SAP/iot-edge-services-samples/tree/master/streaming-aggregation/LICENSE)
